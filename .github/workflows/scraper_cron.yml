name: Executar Scraper a Cada Hora

on:
  # O agendamento cron: No minuto 30 de TODA hora (a cada 60 minutos).
  schedule:
    - cron: '30 * * * *'
  
  # Permite disparar o workflow manualmente pela aba Actions do GitHub
  workflow_dispatch:

jobs:
  run_scraper:
    runs-on: ubuntu-latest
    
    # üåü CORRE√á√ÉO DO ERRO DE PERMISS√ÉO: Adiciona permiss√£o de escrita para o token padr√£o.
    permissions:
      contents: write

    steps:
      # Passo 1: Clona o reposit√≥rio. (Usar√° o token padr√£o com permiss√£o de escrita)
      - name: Checkout code
        uses: actions/checkout@v4
        # O par√¢metro 'with: token' foi removido!

      # Passo 2: Configura o ambiente Python 3.10
      - name: Setup Python environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' 

      # PASSO 3: Instala o Chrome e o ChromeDriver
      - name: Setup Google Chrome and ChromeDriver
        uses: browser-actions/setup-chrome@v1 
        with:
          chrome-version: 'stable' 

      # Passo 4: Instala as depend√™ncias Python
      - name: Install Python dependencies
        run: |
          pip install selenium PyGithub
          
      # Passo 5: Executa o script Python
      - name: Run Python Scraper
        # O CRON_GITHUB_TOKEN √© usado AQUI, para a biblioteca PyGithub (salvar_no_github)
        env:
          CRON_GITHUB_TOKEN: ${{ secrets.CRON_GITHUB_TOKEN }}
        run: python scraper_canais.py
