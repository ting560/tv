name: Executar Scraper a Cada Hora

on:
  # O agendamento cron: No minuto 30 de TODA hora (a cada 60 minutos).
  schedule:
    - cron: '30 * * * *'
  
  # Permite disparar o workflow manualmente pela aba Actions do GitHub
  workflow_dispatch:

jobs:
  run_scraper:
    runs-on: ubuntu-latest

    steps:
      # Passo 1: Clona o repositório.
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.CRON_GITHUB_TOKEN }}

      # Passo 2: Configura o ambiente Python 3.10
      - name: Setup Python environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' 

      # PASSO 3 (NOVO): Instala o Chrome e o ChromeDriver (MAIS ESTÁVEL)
      - name: Setup Google Chrome and ChromeDriver
        uses: browser-actions/setup-chrome@v1 # Usa uma Action dedicada!
        with:
          # Versão 'stable' garantida
          chrome-version: 'stable' 

      # Passo 4: Instala as dependências Python (apenas Selenium e PyGithub)
      - name: Install Python dependencies
        run: |
          # Não precisa mais do webdriver-manager
          pip install selenium PyGithub
          
      # Passo 5: Executa o script Python
      - name: Run Python Scraper
        # 'env' injeta o Token que você salvou no Secret do GitHub
        env:
          CRON_GITHUB_TOKEN: ${{ secrets.CRON_GITHUB_TOKEN }}
        run: python scraper_canais.py
