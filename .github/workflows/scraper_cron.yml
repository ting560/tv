name: Executar Scraper a Cada Hora

on:
  # O agendamento cron: No minuto 30 de TODA hora.
  schedule:
    - cron: '30 * * * *'
  
  # Permite disparar o workflow manualmente
  workflow_dispatch:

jobs:
  run_scraper:
    runs-on: ubuntu-latest

    steps:
      # Passo 1: Clona o repositório
      - name: Checkout code
        uses: actions/checkout@v4
        # Garante que o Checkout tenha permissão para fazer o commit de volta
        with:
          token: ${{ secrets.CRON_GITHUB_TOKEN }}

      # Passo 2: Configura o ambiente Python
      - name: Setup Python environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' 

      # Passo 3: Instala as dependências e o navegador Chromium
      - name: Install dependencies and Chromium
        run: |
          # 1. Instala as libs Python
          pip install selenium PyGithub
          # 2. Instala o navegador Chromium (que o Selenium usará)
          sudo apt-get update 
          sudo apt-get install -y chromium-browser

      # Passo 4: Executa o script Python
      - name: Run Python Scraper
        # 'env' injeta o Token do GitHub que você salvou como Secret
        env:
          CRON_GITHUB_TOKEN: ${{ secrets.CRON_GITHUB_TOKEN }}
        run: python scraper_canais.py
